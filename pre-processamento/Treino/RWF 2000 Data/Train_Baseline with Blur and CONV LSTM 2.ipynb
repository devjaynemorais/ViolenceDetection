{"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"qba8yT9LfHGC"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39137,"status":"ok","timestamp":1652210153628,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"WeYzkkpfHcyj","outputId":"6e37ac1c-fcf3-4355-8f1b-145f46252e4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7330,"status":"ok","timestamp":1652210160922,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"NdeEB8Lkkjo_","outputId":"02d456f7-8265-450c-bac9-6fed339ea8f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n","The following packages were automatically installed and are no longer required:\n","  libnvidia-common-460 nsight-compute-2020.2.0\n","Use 'apt autoremove' to remove them.\n","0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n","\u001b[K     |████████████████████████████████| 647 kB 6.1 MB/s \n","\u001b[K     |████████████████████████████████| 280 kB 82.6 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 83.2 MB/s \n","\u001b[?25h  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!apt-get install ffmpeg\n","!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n","!pip install -q mediapy swifter\n","\n","# !pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110\n","# !pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HjNmPheSlU2m","executionInfo":{"status":"ok","timestamp":1652210165115,"user_tz":180,"elapsed":4206,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["import os\n","import glob\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow.compat.v1 as tf_v1\n","import logging\n","import numpy as np\n","import cupy as cp\n","import mediapy\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","from tqdm import tqdm\n","import cv2\n","from time import sleep\n","from time import time\n","import mediapy as media\n","import shutil\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import ConvLSTM2D, Conv3D\n","from tensorflow.keras.layers import Reshape, AveragePooling2D \n","from tensorflow.keras.layers import Dense, Dropout, Input \n","from tensorflow.keras.layers import BatchNormalization \n","from tensorflow.keras.layers import Flatten \n","from tensorflow.keras.layers import MaxPooling3D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import LSTM, Multiply\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import tensorflow.keras.backend as K\n","\n","from tensorflow import optimizers\n","\n","tf.config.set_soft_device_placement(True)\n","# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false'\n","tf.get_logger().setLevel(logging.ERROR)"]},{"cell_type":"markdown","source":["## Teste"],"metadata":{"id":"nZaHZl7afD2F"}},{"cell_type":"code","source":["video = media.read_video('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train/Robbery035_x264-a4f337e6cb_1_resized_blur.mp4')\n","video_tensor = tf.constant([video[:32]], dtype=tf.float32)"],"metadata":{"id":"73H48AbIQOnv","executionInfo":{"status":"ok","timestamp":1652210278278,"user_tz":180,"elapsed":113199,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True)\n","\n","result = lstm(video_tensor)\n","result.shape # (samples, timesteps, new_rows, new_cols, filters)"],"metadata":{"id":"GfuFaJqiP0ii","executionInfo":{"status":"ok","timestamp":1652210289939,"user_tz":180,"elapsed":11680,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d939e13f-5d44-49cc-e676-f62823f4453f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 32, 224, 224, 256])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHAey5MHiZdk","executionInfo":{"status":"ok","timestamp":1652210291066,"user_tz":180,"elapsed":1162,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"3607a1b8-1772-45c7-b15e-46bce82defb1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","SHAPE BLOCO CONV 3: (1, 2, 7, 7, 64) = 6272 values. \n","SHAPE BLOCO CONV 4: (1, 1, 3, 3, 64) = 576 values. \n","SHAPE BLOCO CONV 5: (1, 0, 1, 1, 128) = 0 values. \n"]}]},{"cell_type":"code","source":["rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","\"\"\"x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\"\"\"\n","\n","#Em paralelo com o x de cima\"\n","\n","\n","lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","print('ConvLSTM2D 1: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","\n","lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","print('ConvLSTM2D 2: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,3,3))(lstm)\n","print('ConvLSTM2D 3: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ajtR51eRq22","executionInfo":{"status":"ok","timestamp":1652210291067,"user_tz":180,"elapsed":15,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"01613c5d-07a5-4ade-d284-d632451e72f6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","ConvLSTM2D 1: (1, 2, 7, 7, 32) = 3136 values. \n","ConvLSTM2D 2: (1, 2, 7, 7, 64) = 6272 values. \n","ConvLSTM2D 3: (1, 2, 4, 4, 128) = 4096 values. \n"]}]},{"cell_type":"code","source":["# https://arxiv.org/pdf/1709.06531.pdf\n","# Learning to detect violence videos using convolutional long short-term memory. 2017.\n","# https://github.com/aggression-detect/aggression_detect/blob/eedbaf3ab15595998ea8af1620c237d68318a42f/LSTM_CNN/BuildModel_basic.py\n","rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","\"\"\"x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\"\"\"\n","\n","#Em paralelo com o x de cima\"\n","\n","# cnn = TimeDistributed(cnn)(input_layer)\n","\n","lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","print('ConvLSTM2D 1: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","\n","#lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","lstm = Flatten()(lstm)\n","print('Flatten 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","dropout = 0.5\n","lstm = BatchNormalization()(lstm)\n","print('BatchNormalization 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dense(1000)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dense(256)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Dense(10)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","#activation = 'sigmoid'\n","#loss_func = 'binary_crossentropy'\n","\n","\n","#FALTA A ÚLTIMA CAMADA DENSA\n","\n","\n","\n","\"\"\"if classes > 1:\n","    activation = 'softmax'\n","    loss_func = 'categorical_crossentropy'\n","predictions = Dense(classes,  activation=activation)(relu)\n","\n","\n","model = Model(inputs=input_layer, outputs=predictions)\n","optimizer = optimizer_class[0](lr=learning_rate, **optimizer_class[1])\n","model.compile(optimizer=optimizer, loss=loss_func,metrics=['acc'])\n","\n","print(model.summary())\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"I-Fxkhc4eNbD","executionInfo":{"status":"ok","timestamp":1652210292291,"user_tz":180,"elapsed":586,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"b6237c6c-eb4a-4aab-df20-43f0ce001b65"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","ConvLSTM2D 1: (1, 4, 14, 14, 256) = 200704 values. \n","Flatten 1: (1, 200704) = x values. \n","BatchNormalization 1: (1, 200704) = x values. \n","Dropout 1: (1, 200704) = x values. \n","Dense 1: (1, 1000) = x values. \n","Activation: (1, 1000) = x values. \n","Dense 1: (1, 256) = x values. \n","Dropout 1: (1, 256) = x values. \n","Activation: (1, 256) = x values. \n","Dense 1: (1, 10) = x values. \n","Dropout 1: (1, 10) = x values. \n","Activation: (1, 10) = x values. \n"]},{"output_type":"execute_result","data":{"text/plain":["\"if classes > 1:\\n    activation = 'softmax'\\n    loss_func = 'categorical_crossentropy'\\npredictions = Dense(classes,  activation=activation)(relu)\\n\\n\\nmodel = Model(inputs=input_layer, outputs=predictions)\\noptimizer = optimizer_class[0](lr=learning_rate, **optimizer_class[1])\\nmodel.compile(optimizer=optimizer, loss=loss_func,metrics=['acc'])\\n\\nprint(model.summary())\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAU2MEuDJpSr","executionInfo":{"status":"ok","timestamp":1652210292293,"user_tz":180,"elapsed":34,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"b3f834d9-4544-460d-e16d-87814235601d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 4, 14, 14, 32])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["32*14*14*32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uK1N9NcbJYlT","executionInfo":{"status":"ok","timestamp":1652210292294,"user_tz":180,"elapsed":28,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"c6416846-db91-4e77-a7a7-df1d9473960a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200704"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# Início"],"metadata":{"id":"kShteWft-dGB"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"2b0LosEhvgA0","executionInfo":{"status":"ok","timestamp":1652210292296,"user_tz":180,"elapsed":23,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["# Paths base\n","PATH_BASE = '/content/drive/MyDrive/ucf_experiments/'\n","PATH_CICLE = PATH_BASE + 'ciclo_experimental_1/'\n","\n","# Path base de armazenamento dos augmentations\n","PATH_DATA = PATH_CICLE + 'data/'\n","\n","# Dados de treino augmentados\n","#PATH_AUG_BASE = PATH_DATA + 'augmented_train/'\n","# Dados de teste redimensionados (visto que não popdem ser augmentados)\n","#PATH_TEST_RESIZED = PATH_DATA + 'resized_test/'\n","\n","PATH_BLUR_CONVLSTM = PATH_DATA + 'data_blur_convlstm2/' #data_blur\n","PATH_BLUR = PATH_DATA + 'data_blur/' #data_blur"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1652210292721,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"RlpTDpPZv5dp","outputId":"0deeddcc-c882-4e67-c55a-b37a63e825b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/model/  already exists\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/model/checkpoints/  already exists\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/model/runs/  already exists\n"]}],"source":["# Create target directory & all intermediate directories if don't exists\n","def create_dir(dirName):\n","  try:\n","      os.makedirs(dirName) \n","      print(dirName)   \n","      print(\"Directory \" , dirName ,  \" Created \")\n","      return dirName\n","  except FileExistsError:\n","      print(\"Directory \" , dirName ,  \" already exists\")  \n","      return dirName\n","\n","\n","PATH_BLUR_CONVLSTM_MODEL = create_dir(PATH_BLUR_CONVLSTM + 'model/')\n","PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS = create_dir(PATH_BLUR_CONVLSTM_MODEL + 'checkpoints/')\n","PATH_TENSORBOARD = create_dir(PATH_BLUR_CONVLSTM_MODEL + 'runs/')"]},{"cell_type":"markdown","metadata":{"id":"26PzXiHKhPGA"},"source":["## Uniform Sample"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1652210293421,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"a8voaKPMjC_E","outputId":"6e63c9c2-5e81-412b-a20c-fa21d2811f59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/train/  already exists\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/train/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/test/  already exists\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/test/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/checkpoints_train/  already exists\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/checkpoints_train/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/checkpoints_test/  already exists\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/uniform_samples/checkpoints_test/\n"]}],"source":["PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TRAIN = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/train/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TRAIN)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TEST = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/test/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TEST)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TRAIN = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/checkpoints_train/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TRAIN)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TEST = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/checkpoints_test/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TEST)"]},{"cell_type":"code","source":["# Copiando os dados do experimento data_blur para este (data_blur_lstm)\n","# PATH_BLUR -> PATH_BLUR_CONVLSTM\n","\n","source=PATH_BLUR + 'train_uniform_sample_rwf2000.txt'\n","destination=PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt'\n","shutil.copyfile(source, destination)\n","\n","source=PATH_BLUR + 'test_uniform_sample_rwf2000.txt'\n","destination=PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt'\n","shutil.copyfile(source, destination)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"PtRWuFK-B958","executionInfo":{"status":"ok","timestamp":1652210296239,"user_tz":180,"elapsed":2824,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"8ba30919-ed96-4e1f-8479-331cdb4c4495"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm2/test_uniform_sample_rwf2000.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2gJVcEa5oROu","executionInfo":{"status":"ok","timestamp":1652210296241,"user_tz":180,"elapsed":52,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["train_dataset = pd.read_csv(PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', sep=';', names=['video_path', 'label', 'new_path'])\n","test_dataset = pd.read_csv(PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt', sep=';', names=['video_path', 'label', 'new_path'])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TuJoG22A94aS","executionInfo":{"status":"ok","timestamp":1652210296243,"user_tz":180,"elapsed":52,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"6d5f6cdf-15ed-4695-870f-f41213587d88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"train_dataset = train_dataset.loc[\\n                                  (train_dataset.video_path.str.contains('_x264_') |\\n                                   ~train_dataset.video_path.str.contains('_x264-')) & \\n                                  (train_dataset.video_path.str.contains('resized'))]\\n\\ntest_dataset = test_dataset.loc[\\n                                (test_dataset.video_path.str.contains('_x264_') | \\n                                 ~test_dataset.video_path.str.contains('_x264-')) &\\n                                (test_dataset.video_path.str.contains('resized'))]\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["\"\"\"train_dataset = train_dataset.loc[\n","                                  (train_dataset.video_path.str.contains('_x264_') |\n","                                   ~train_dataset.video_path.str.contains('_x264-')) & \n","                                  (train_dataset.video_path.str.contains('resized'))]\n","\n","test_dataset = test_dataset.loc[\n","                                (test_dataset.video_path.str.contains('_x264_') | \n","                                 ~test_dataset.video_path.str.contains('_x264-')) &\n","                                (test_dataset.video_path.str.contains('resized'))]\"\"\""]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1652210296244,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"6Cs2L1m3-nJd","outputId":"3997c122-ce38-4030-9bf1-6cfa689db2b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400, 3)"]},"metadata":{},"execution_count":17}],"source":["test_dataset.shape"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1652210296244,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"-hA_psPy-ljN","outputId":"e7054f9b-ce7a-45f9-9e2d-02c95adad327"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1600, 3)"]},"metadata":{},"execution_count":18}],"source":["train_dataset.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"RR3ZjfOE44wL","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1652210296245,"user_tz":180,"elapsed":33,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"19c7d5ba-7c72-4dec-b6e7-54ab4e5e932a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"train_dataset.to_csv(PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\\ntest_dataset.to_csv(PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["\"\"\"train_dataset.to_csv(PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\n","test_dataset.to_csv(PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\"\"\""]},{"cell_type":"code","source":["train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"9sDRF1h29fMi","executionInfo":{"status":"ok","timestamp":1652210296245,"user_tz":180,"elapsed":29,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"4ec0c72b-8905-40f1-f65d-c9734aba19ed"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             video_path  label  new_path\n","0     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","1     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","2     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","3     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","4     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","...                                                 ...    ...       ...\n","1595  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1596  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1597  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1598  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1599  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","\n","[1600 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-2478d819-2a28-4246-bf1d-25895a957520\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_path</th>\n","      <th>label</th>\n","      <th>new_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1595</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1596</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1597</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1598</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1599</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1600 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2478d819-2a28-4246-bf1d-25895a957520')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2478d819-2a28-4246-bf1d-25895a957520 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2478d819-2a28-4246-bf1d-25895a957520');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"jHLR25qXoYXc","executionInfo":{"status":"ok","timestamp":1652210296246,"user_tz":180,"elapsed":27,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["max_batch_size = 5\n","\n","train_dataset_list = train_dataset.new_path.tolist()\n","train_label_list = train_dataset.label.tolist()\n","\n","test_dataset_list = test_dataset.new_path.tolist()\n","test_label_list = test_dataset.label.tolist()\n","NUM_WORKERS=4\n","EPOCHS=60\n","BATCH_SIZE=8\n","\n","N_CLASSES = 2\n","IMSIZE = (224, 224)\n","SequenceLength = 64\n","\n","STEPS_PER_EPOCH = int(len(train_dataset_list) / BATCH_SIZE)\n","VAL_STEPS_PER_EPOCH = int(len(test_dataset_list) / BATCH_SIZE)\n","\n","shapes = ((BATCH_SIZE, SequenceLength, IMSIZE[0], IMSIZE[1], 3), (BATCH_SIZE, N_CLASSES))\n","dtypes = (tf.float32, tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"xZPVeX2wSUXw"},"source":["# Treino"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"YPO9em86MYfW","executionInfo":{"status":"ok","timestamp":1652210296246,"user_tz":180,"elapsed":26,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["from keras.models import Sequential, Input, Model\n","from keras.models import load_model\n","from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n","from keras.regularizers import l2\n","from keras.layers.core import Lambda\n","from keras.layers.core import Lambda\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras import mixed_precision"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"qxp-7Jn8tglv","executionInfo":{"status":"ok","timestamp":1652210296247,"user_tz":180,"elapsed":26,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["from tensorflow.keras import mixed_precision\n","\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_global_policy(policy)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"f7lThedsDCB3","executionInfo":{"status":"ok","timestamp":1652210296247,"user_tz":180,"elapsed":25,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["# def load_pretrained_model():\n","#   sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","#   model = load_model('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/keras_model.h5')\n","\n","#   model.compile(optimizer=sgd,\n","#                 loss='categorical_crossentropy',\n","#                 metrics=['accuracy'])\n","  \n","#   return model"]},{"cell_type":"markdown","source":["## Model 0"],"metadata":{"id":"x9NDZQxFLzM2"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"imqOkNqLMYdQ","executionInfo":{"status":"ok","timestamp":1652210296248,"user_tz":180,"elapsed":26,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["def create_model(continue_training=False, last_checkpoint=0):\n","  metrics=[\n","    tf.keras.metrics.Precision(),\n","    tf.keras.metrics.CategoricalAccuracy(),\n","    tf.keras.metrics.Recall(),\n","    tf.keras.metrics.AUC()\n","  ]\n","\n","  inputs = Input(shape=(SequenceLength, IMSIZE[0], IMSIZE[1], 3))\n","\n","  #####################################################\n","  rgb = inputs\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","\n","  ##############################################\n","  ##############################################\n","\n","  #https://github.com/satyachaurasia/Violence-Detection-using-ConvLSTM/blob/master/ViolentModel.py\n","  #file:///C:/Users/jayne/Documents/Mestrado/Artigos%20coletados/A%20Frame-Based%20Feature%20Model%20for%20Violence%20Detection%20from%20Surveillance%20Cameras%20Using%20ConvLSTM%20Network.pdf\n","  #https://github.com/CankayaUniversity/ceng-407-408-2020-2021-Violent-Activity-Detection-from-Videos/blob/main/model.ipynb\n","  #https://www.programcreek.com/python/example/120287/keras.layers.ConvLSTM2D\n","\n","  #3 blocos ConvLSTM + Fully conected\n","\n","  lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(rgb)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","\n","  #lstm = Dropout(0.4)(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(lstm)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(lstm)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","\n","  lstm = BatchNormalization()(lstm)\n","\n","  ##############################################\n","  ##############################################\n","\n","\n","  #Model \n","  #lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(inputs)\n","\n","\n","  ##################################################### Fusion and Pooling\n","  #x = Multiply()([rgb, lstm])\n","  x = MaxPooling3D(pool_size=(8,1,1))(lstm)\n","\n","  ##################################################### Merging Block\n","\n","  \"\"\"lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  lstm = Flatten()(lstm)\n","  dropout = 0.5\n","  lstm = BatchNormalization()(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Dense(1000)(lstm)\n","  lstm = Activation('relu')(lstm)\n","  lstm = Dense(256)(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Activation('relu')(lstm)\"\"\"\n","\n","\n","  \n","  \"\"\"x = Conv3D(\n","      64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","  x = Conv3D(\n","      64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","  x = Conv3D(\n","      128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,3,3))(x)\"\"\"\n","\n","  #####################################################\n","  x = Flatten()(x)\n","\n","\n","  x = Dense(128,activation='relu')(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(32, activation='relu')(x)\n","  pred = Dense(N_CLASSES, activation='softmax', dtype='float32')(x)\n","  model = Model(inputs=inputs, outputs=pred)\n","\n","  sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n","\n","  return model"]},{"cell_type":"markdown","source":["## Model 2\n"],"metadata":{"id":"dZNS-1DHL8A5"}},{"cell_type":"code","source":["def create_model1(continue_training=False, last_checkpoint=0):\n","  metrics=[\n","    tf.keras.metrics.Precision(),\n","    tf.keras.metrics.CategoricalAccuracy(),\n","    tf.keras.metrics.Recall(),\n","    tf.keras.metrics.AUC()\n","  ]\n","\n","  inputs = Input(shape=(SequenceLength, IMSIZE[0], IMSIZE[1], 3))\n","\n","  #####################################################\n","  rgb = inputs\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","\n","  #####################################################\n","  x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","\n","\n","  #####################################################\n","\n","  # cnn = TimeDistributed(cnn)(input_layer)\n","  lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  #lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  #lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  lstm = BatchNormalization()(lstm)\n","\n","  \"\"\"  lstm = Flatten()(lstm)\n","  dropout = 0.5\n","  #lstm = BatchNormalization()(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Dense(1000)(lstm)\n","  lstm = Activation('relu')(lstm)\n","  lstm = Dense(256)(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Activation('relu')(lstm)\"\"\"\n","\n","\n","  #####################################################\n","  x = Flatten()(lstm)\n","  x = Dense(128,activation='relu')(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(32, activation='relu')(x)\n","  pred = Dense(2, activation='softmax')(x)\n","  model = Model(inputs=inputs, outputs=pred)\n","\n","  sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n","\n","  return model"],"metadata":{"id":"PUCc9Ru-xg0d","executionInfo":{"status":"ok","timestamp":1652210296248,"user_tz":180,"elapsed":25,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["model = create_model1()\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPB5-fvqYfA3","executionInfo":{"status":"ok","timestamp":1652210297566,"user_tz":180,"elapsed":1342,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"cc5dc5b8-a076-4779-cb95-d89eaa93ec1d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 64, 224, 224, 3)  0         \n","                             ]                                   \n","                                                                 \n"," conv3d_30 (Conv3D)          (None, 64, 224, 224, 16)  448       \n","                                                                 \n"," conv3d_31 (Conv3D)          (None, 64, 224, 224, 16)  784       \n","                                                                 \n"," max_pooling3d_21 (MaxPoolin  (None, 64, 112, 112, 16)  0        \n"," g3D)                                                            \n","                                                                 \n"," conv3d_32 (Conv3D)          (None, 64, 112, 112, 16)  2320      \n","                                                                 \n"," conv3d_33 (Conv3D)          (None, 64, 112, 112, 16)  784       \n","                                                                 \n"," max_pooling3d_22 (MaxPoolin  (None, 64, 56, 56, 16)   0         \n"," g3D)                                                            \n","                                                                 \n"," conv3d_34 (Conv3D)          (None, 64, 56, 56, 32)    4640      \n","                                                                 \n"," conv3d_35 (Conv3D)          (None, 64, 56, 56, 32)    3104      \n","                                                                 \n"," max_pooling3d_23 (MaxPoolin  (None, 64, 28, 28, 32)   0         \n"," g3D)                                                            \n","                                                                 \n"," conv3d_36 (Conv3D)          (None, 64, 28, 28, 32)    9248      \n","                                                                 \n"," conv3d_37 (Conv3D)          (None, 64, 28, 28, 32)    3104      \n","                                                                 \n"," max_pooling3d_24 (MaxPoolin  (None, 64, 14, 14, 32)   0         \n"," g3D)                                                            \n","                                                                 \n"," max_pooling3d_25 (MaxPoolin  (None, 8, 14, 14, 32)    0         \n"," g3D)                                                            \n","                                                                 \n"," conv_lstm2d_10 (ConvLSTM2D)  (None, 8, 14, 14, 256)   2655232   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 8, 14, 14, 256)   1024      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten_1 (Flatten)         (None, 401408)            0         \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               51380352  \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 54,065,234\n","Trainable params: 54,064,722\n","Non-trainable params: 512\n","_________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":28,"metadata":{"id":"xX2Uu0gDfHOp","executionInfo":{"status":"ok","timestamp":1652210297568,"user_tz":180,"elapsed":28,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["import tensorflow.keras as keras\n","from tensorflow.keras.utils import Sequence\n","from keras.utils import np_utils\n","import mediapy as media\n","\n","class DataGenerator(Sequence):\n","    \"\"\"Data Generator inherited from keras.utils.Sequence\n","    Args: \n","        directory: the path of data set, and each sub-folder will be assigned to one class\n","        batch_size: the number of data points in each batch\n","        shuffle: whether to shuffle the data per epoch\n","    Note:\n","        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n","    \"\"\"\n","    def __init__(self, input_file, batch_size=1, shuffle=True, data_augmentation=True, uniform_sample=False):\n","        # Initialize the params\n","        self.batch_size = batch_size\n","        self.input_file = input_file\n","        self.classes = 2\n","        self.shuffle = shuffle\n","        self.data_aug = data_augmentation\n","        self.uniform_sample = uniform_sample\n","        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n","        self.X_path, self.Y_dict = self.search_data() \n","        # Print basic statistics information\n","        self.print_stats()\n","        return None\n","        \n","    def search_data_v2(self):\n","        X_path = []\n","        Y_dict = {}\n","        \"\"\"one_hots = np_utils.to_categorical(range(self.classes))\n","\n","        with open(self.input_file, 'r') as data_file:\n","           for line in data_file:\n","              line = line.rstrip('\\n')\n","              path = line[:-2]\n","\n","              label = int(line[-1:])\n","              X_path.append(path)\n","              Y_dict[path] = one_hots[label]\"\"\"\n","\n","        # # list all kinds of sub-folders\n","        # self.dirs = sorted(os.listdir(self.directory))\n","        # one_hots = np_utils.to_categorical(range(len(self.dirs)))\n","        # for i,folder in enumerate(self.dirs):\n","        #     folder_path = os.path.join(self.directory,folder)\n","        #     for file in os.listdir(folder_path):\n","        #         file_path = os.path.join(folder_path,file)\n","        #         # append the each file path, and keep its label  \n","        #         X_path.append(file_path)\n","        #         Y_dict[file_path] = one_hots[i]\n","\n","        df_videos = pd.read_csv(self.input_file, header=None, sep=';', names=['video_path', 'label', 'frames32'])\n","        df_videos_filtered = df_videos.loc[df_videos.frames32 == 0]\n","\n","        X_path = df_videos_filtered[['video_path', 'label']].video_path.to_list()\n","        Y_dict = pd.get_dummies(df_videos_filtered[['video_path', 'label']], columns=['label']).set_index('video_path').T.to_dict(orient=\"list\")\n","\n","        return X_path, Y_dict\n","\n","    def search_data(self):\n","        X_path = []\n","        Y_dict = {}\n","        one_hots = np_utils.to_categorical(range(self.classes))\n","\n","        with open(self.input_file, 'r') as data_file:\n","           for line in data_file:\n","              line = line.rstrip('\\n').split(';')\n","              path = line[0]\n","\n","              label = int(line[1])\n","              X_path.append(path)\n","              Y_dict[path] = one_hots[label]\n","\n","        return X_path, Y_dict\n","    \n","    def print_stats(self):\n","        # calculate basic information\n","        self.n_files = len(self.X_path)\n","        self.n_classes = self.classes\n","        self.indexes = np.arange(len(self.X_path))\n","        np.random.shuffle(self.indexes)\n","        # Output states\n","        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n","        for i,label in enumerate(range(self.classes)):\n","            print('%10s : '%(label),i)\n","        return None\n","    \n","    def __len__(self):\n","        # calculate the iterations of each epoch\n","        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n","        return int(steps_per_epoch)\n","\n","    def __getitem__(self, index):\n","        \"\"\"Get the data of each batch\n","        \"\"\"\n","        # get the indexs of each batch\n","        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # using batch_indexs to get path of current batch\n","        batch_path = [self.X_path[k] for k in batch_indexs]\n","        # get batch data\n","        batch_x, batch_y = self.data_generation(batch_path)\n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        # shuffle the data at each end of epoch\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def data_generation(self, batch_path):\n","        # load data into memory, you can change the np.load to any method you want\n","        batch_x = [self.load_data(x) for x in batch_path]\n","        batch_y = [self.Y_dict[x] for x in batch_path]\n","        # transfer the data format and take one-hot coding for labels\n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","        return batch_x, batch_y\n","      \n","    def normalize(self, data):\n","        mean = np.mean(data)\n","        std = np.std(data)\n","        return (data-mean) / std\n","    \n","    def random_flip(self, video, prob):\n","        s = np.random.rand()\n","        if s < prob:\n","            video = np.flip(m=video, axis=2)\n","        return video    \n","    \n","    def uniform_sampling(self, video, target_frames=64):\n","        # get total frames of input video and calculate sampling interval \n","        len_frames = int(len(video))\n","        interval = int(np.ceil(len_frames/target_frames))\n","        # init empty list for sampled video and \n","        sampled_video = []\n","        for i in range(0,len_frames,interval):\n","            sampled_video.append(video[i])     \n","        # calculate numer of padded frames and fix it \n","        num_pad = target_frames - len(sampled_video)\n","        if num_pad>0:\n","            padding = [video[i] for i in range(-num_pad,0)]\n","            sampled_video += padding     \n","        # get sampled video\n","\n","        #sampled_video = tf.image.resize(sampled_video, [224,224])\n","        return np.array(sampled_video, dtype=np.float32)\n","    \n","    def dynamic_crop(self, video):\n","        # extract layer of optical flow from video\n","        opt_flows = video[...,3]\n","        # sum of optical flow magnitude of individual frame\n","        magnitude = np.sum(opt_flows, axis=0)\n","        # filter slight noise by threshold \n","        thresh = np.mean(magnitude)\n","        magnitude[magnitude<thresh] = 0\n","        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n","        x_pdf = np.sum(magnitude, axis=1) + 0.001\n","        y_pdf = np.sum(magnitude, axis=0) + 0.001\n","        # normalize PDF of x and y so that the sum of probs = 1\n","        x_pdf /= np.sum(x_pdf)\n","        y_pdf /= np.sum(y_pdf)\n","        # randomly choose some candidates for x and y \n","        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n","        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n","        # get the mean of x and y coordinates for better robustness\n","        x = int(np.mean(x_points))\n","        y = int(np.mean(y_points))\n","        # avoid to beyond boundaries of array\n","        x = max(56,min(x,167))\n","        y = max(56,min(y,167))\n","        # get cropped video \n","        return video[:,x-56:x+56,y-56:y+56,:]  \n","    \n","    def color_jitter(self,video):\n","        # range of s-component: 0-1\n","        # range of v component: 0-255\n","        s_jitter = np.random.uniform(-0.2,0.2)\n","        v_jitter = np.random.uniform(-30,30)\n","        for i in range(len(video)):\n","            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n","            s = hsv[...,1] + s_jitter\n","            v = hsv[...,2] + v_jitter\n","            s[s<0] = 0\n","            s[s>1] = 1\n","            v[v<0] = 0\n","            v[v>255] = 255\n","            hsv[...,1] = s\n","            hsv[...,2] = v\n","            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n","        return video\n","        \n","    def load_data(self, path):\n","        data = media.read_video(path)[...,:3]\n","        data = np.float32(data)\n","        # sampling 64 frames uniformly from the entire video\n","\n","        if self.uniform_sample:\n","          data = self.uniform_sampling(video=data, target_frames=64)\n","        else:\n","          data = np.array(data, dtype=np.float32)\n","\n","        # whether to utilize the data augmentation\n","        if  self.data_aug:\n","            data = self.color_jitter(data)\n","            data = self.random_flip(data, prob=0.5)\n","        # normalize\n","\n","        data = self.normalize(data)\n","        return data"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"ixYRmjWoMsBo","executionInfo":{"status":"ok","timestamp":1652210297570,"user_tz":180,"elapsed":28,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["import keras.backend as K\n","from keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch):\n","    # Every 10 epochs, the learning rate is reduced to 1/10 of the original\n","    if epoch % 10 == 0 and epoch != 0:\n","        lr = K.get_value(model.optimizer.lr)\n","        K.set_value(model.optimizer.lr, lr * 0.5)\n","    return K.get_value(model.optimizer.lr)"]},{"cell_type":"code","source":["train_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train_uniform_sample_rwf2000.txt', \n","                            batch_size=BATCH_SIZE, \n","                            data_augmentation=True,\n","                            uniform_sample=False)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KR2MR48v46qI","executionInfo":{"status":"ok","timestamp":1652210297571,"user_tz":180,"elapsed":27,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"dd96596b-3a99-4d53-8cc7-e5e0cd213aa9"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n"]}]},{"cell_type":"code","source":["batch = next(iter(train_generator))"],"metadata":{"id":"yCqRXKnJ49IJ","executionInfo":{"status":"ok","timestamp":1652210398108,"user_tz":180,"elapsed":100551,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["batch[0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqT-lI2U5bYY","executionInfo":{"status":"ok","timestamp":1652210398110,"user_tz":180,"elapsed":58,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"0b5a8d85-591a-4e39-e27e-0195240ba562"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 224, 224, 3)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["with tf.device('/gpu:0'):  \n","  # train_pipe = video_pipe(\n","  #     file_list=train_dataset_list,\n","  #     label_list=train_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # train_generator = dali_tf.DALIDataset(\n","  #       pipeline=train_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0\n","  # )\n","\n","  # test_pipe = video_pipe(\n","  #     file_list=test_dataset_list,\n","  #     label_list=test_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # test_generator = dali_tf.DALIDataset(\n","  #       pipeline=test_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0 \n","  # )\n","\n","  train_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train_uniform_sample_rwf2000.txt', \n","                              batch_size=BATCH_SIZE, \n","                              data_augmentation=True,\n","                              uniform_sample=False)\n","    \n","  val_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/test_uniform_sample_rwf2000.txt',\n","                                batch_size=BATCH_SIZE, \n","                                data_augmentation=False,\n","                                uniform_sample=False)\n","\n","  \n","  model = create_model1()\n","\n","  reduce_lr = LearningRateScheduler(scheduler)\n","  tb_callback = tf.keras.callbacks.TensorBoard(PATH_TENSORBOARD, update_freq=1)\n","  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS + \"model.{epoch:02d}.h5\",\n","                                                  save_weights_only=False,\n","                                                  verbose=1)\n","  \n","  callbacks_list = [reduce_lr, tb_callback, cp_callback]\n","  \n","  hist = model.fit(\n","    train_generator, \n","    validation_data=val_generator,\n","    validation_steps=VAL_STEPS_PER_EPOCH,\n","    callbacks=callbacks_list,\n","    workers=16,\n","    max_queue_size=8, \n","    verbose=1, \n","    epochs=EPOCHS,\n","    steps_per_epoch=STEPS_PER_EPOCH,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SfhofjbBiwKO","executionInfo":{"status":"error","timestamp":1652210443673,"user_tz":180,"elapsed":45612,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"62109bdb-3c94-4f12-814c-3676f3424abc"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n","Found 400 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n","Epoch 1/60\n","  7/200 [>.............................] - ETA: 3:50 - loss: 44.3152 - precision_1: 0.5357 - categorical_accuracy: 0.5357 - recall_1: 0.5357 - auc_1: 0.5408"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-db28fa1663ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     steps_per_epoch=STEPS_PER_EPOCH,)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-33-db28fa1663ac>\", line 62, in <module>\n      steps_per_epoch=STEPS_PER_EPOCH,)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 1414, in update_state\n      sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 605, in update_confusion_matrix_variables\n      message='predictions must be >= 0'),\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-33-db28fa1663ac>\", line 62, in <module>\n      steps_per_epoch=STEPS_PER_EPOCH,)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 1414, in update_state\n      sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 605, in update_confusion_matrix_variables\n      message='predictions must be >= 0'),\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_6:0) = ] [[nan nan][nan...]...] [y (Cast_8/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]]\n\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_848/_177]]\n  (1) INVALID_ARGUMENT:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (Cast_6:0) = ] [[nan nan][nan...]...] [y (Cast_8/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_13867]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBZQnYw1MsGY","executionInfo":{"status":"aborted","timestamp":1652210443665,"user_tz":180,"elapsed":20,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["with tf.device('/gpu:0'):  \n","  # train_pipe = video_pipe(\n","  #     file_list=train_dataset_list,\n","  #     label_list=train_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # train_generator = dali_tf.DALIDataset(\n","  #       pipeline=train_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0\n","  # )\n","\n","  # test_pipe = video_pipe(\n","  #     file_list=test_dataset_list,\n","  #     label_list=test_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # test_generator = dali_tf.DALIDataset(\n","  #       pipeline=test_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0 \n","  # )\n","\n","  train_generator = DataGenerator(input_file=PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', \n","                              batch_size=BATCH_SIZE, \n","                              data_augmentation=True,\n","                              uniform_sample=False)\n","    \n","  val_generator = DataGenerator(input_file=PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt',\n","                                batch_size=BATCH_SIZE, \n","                                data_augmentation=False,\n","                                uniform_sample=False)\n","\n","  \n","  model = create_model1()\n","\n","  reduce_lr = LearningRateScheduler(scheduler)\n","  tb_callback = tf.keras.callbacks.TensorBoard(PATH_TENSORBOARD, update_freq=1)\n","  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS + \"model.{epoch:02d}.h5\",\n","                                                  save_weights_only=False,\n","                                                  verbose=1)\n","  \n","  callbacks_list = [reduce_lr, tb_callback, cp_callback]\n","  \n","  hist = model.fit(\n","    train_generator, \n","    validation_data=val_generator,\n","    validation_steps=VAL_STEPS_PER_EPOCH,\n","    callbacks=callbacks_list,\n","    workers=16,\n","    max_queue_size=8, \n","    verbose=1, \n","    epochs=EPOCHS,\n","    steps_per_epoch=STEPS_PER_EPOCH,)"]},{"cell_type":"code","source":["def load_pretrained_model():\n","  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model = load_model('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/model_vBaseline_mixed_precision - rwf/checkpoints/model.30.h5')\n","\n","  model.compile(optimizer=sgd,\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","  \n","  return model\n","  \n","model = load_pretrained_model()\n","model.summary()"],"metadata":{"id":"3ZSiR2sVUFhI","executionInfo":{"status":"aborted","timestamp":1652210443666,"user_tz":180,"elapsed":21,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"17zYehb5UtfU","executionInfo":{"status":"aborted","timestamp":1652210443667,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"jZcRA49pUthz","executionInfo":{"status":"aborted","timestamp":1652210443667,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zusm9alrUtk8","executionInfo":{"status":"aborted","timestamp":1652210443668,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMrnr7LeeSIO","executionInfo":{"status":"aborted","timestamp":1652210443668,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XF7onohZbPhW","executionInfo":{"status":"aborted","timestamp":1652210443669,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["train_iter = iter(train_generator)\n","test_iter = iter(test_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVoth2uCZ2XR","executionInfo":{"status":"aborted","timestamp":1652210443669,"user_tz":180,"elapsed":22,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["train_batch = next(train_iter)\n","videos, labels = train_batch\n","mediapy.show_videos(videos)\n","\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7waK-MLPgRQe","executionInfo":{"status":"aborted","timestamp":1652210443670,"user_tz":180,"elapsed":23,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["videos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ql1-dZ_NajIG","executionInfo":{"status":"aborted","timestamp":1652210443670,"user_tz":180,"elapsed":23,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["videos, labels = next(test_iter)\n","\n","mediapy.show_videos(videos.numpy())\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQ4WV0Wtaql8","executionInfo":{"status":"aborted","timestamp":1652210443670,"user_tz":180,"elapsed":23,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay6_FGq4ax2C","executionInfo":{"status":"aborted","timestamp":1652210443671,"user_tz":180,"elapsed":24,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNRxPGbY5zTy","executionInfo":{"status":"aborted","timestamp":1652210443671,"user_tz":180,"elapsed":23,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPSJITGksMws","executionInfo":{"status":"aborted","timestamp":1652210443672,"user_tz":180,"elapsed":24,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["PATH_TENSORBOARD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxgZ5t6ww1Hk","executionInfo":{"status":"aborted","timestamp":1652210443672,"user_tz":180,"elapsed":24,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}}},"outputs":[],"source":["%tensorboard --logdir /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/model/runs/"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Train_Baseline with Blur and CONV LSTM 2.ipynb","provenance":[{"file_id":"1Y0Es-7qp0lKidIvDQtg1A95B_0nM0XUY","timestamp":1649245732503},{"file_id":"1NLkAOAFumeAKxsMA-hR0cFVVxh8s2OVn","timestamp":1649024032719},{"file_id":"12Jwm0NNThnZ4zOtLO9f8NboWGeLCmT97","timestamp":1648915960592},{"file_id":"18_hYXNSngi6puvDFPxZm8zPn_eUOrFDx","timestamp":1648858065542},{"file_id":"1iRVjGGuITI462fWGrokE2svB9ZZt4v5u","timestamp":1643675720779},{"file_id":"16WW39YDTR9IudeyKu3JS86yhUyDUCUT3","timestamp":1640226292514}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}