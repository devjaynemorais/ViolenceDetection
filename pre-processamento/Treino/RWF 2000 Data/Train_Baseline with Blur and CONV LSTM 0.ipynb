{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33813,"status":"ok","timestamp":1652152257172,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"WeYzkkpfHcyj","outputId":"a7efe057-7b94-41f9-83c9-47151c0fe5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8854,"status":"ok","timestamp":1652152273649,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"NdeEB8Lkkjo_","outputId":"44717502-92b8-4e14-8249-8122160bb9df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n","The following packages were automatically installed and are no longer required:\n","  libnvidia-common-460 nsight-compute-2020.2.0\n","Use 'apt autoremove' to remove them.\n","0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n","\u001b[K     |████████████████████████████████| 647 kB 7.5 MB/s \n","\u001b[K     |████████████████████████████████| 280 kB 50.8 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 63.5 MB/s \n","\u001b[?25h  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!apt-get install ffmpeg\n","!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n","!pip install -q mediapy swifter\n","\n","# !pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110\n","# !pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HjNmPheSlU2m"},"outputs":[],"source":["import os\n","import glob\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow.compat.v1 as tf_v1\n","import logging\n","import numpy as np\n","import cupy as cp\n","import mediapy\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","from tqdm import tqdm\n","import cv2\n","from time import sleep\n","from time import time\n","import mediapy as media\n","import shutil\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import ConvLSTM2D, Conv3D\n","from tensorflow.keras.layers import Reshape, AveragePooling2D \n","from tensorflow.keras.layers import Dense, Dropout, Input \n","from tensorflow.keras.layers import BatchNormalization \n","from tensorflow.keras.layers import Flatten \n","from tensorflow.keras.layers import MaxPooling3D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import LSTM, Multiply\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import tensorflow.keras.backend as K\n","\n","from tensorflow import optimizers\n","\n","tf.config.set_soft_device_placement(True)\n","# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false'\n","tf.get_logger().setLevel(logging.ERROR)"]},{"cell_type":"code","source":["video = media.read_video('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train/Robbery035_x264-a4f337e6cb_1_resized_blur.mp4')\n","video_tensor = tf.constant([video[:32]], dtype=tf.float32)"],"metadata":{"id":"73H48AbIQOnv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True)\n","\n","result = lstm(video_tensor)\n","result.shape # (samples, timesteps, new_rows, new_cols, filters)"],"metadata":{"id":"GfuFaJqiP0ii","executionInfo":{"status":"ok","timestamp":1652152410907,"user_tz":180,"elapsed":10219,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7943ccf5-edbe-4e0a-e1c0-0a2030108d89"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 32, 224, 224, 256])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHAey5MHiZdk","executionInfo":{"status":"ok","timestamp":1652152411410,"user_tz":180,"elapsed":522,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"5e486bcb-085c-47c3-ef8d-de95e0e48fee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","SHAPE BLOCO CONV 3: (1, 2, 7, 7, 64) = 6272 values. \n","SHAPE BLOCO CONV 4: (1, 1, 3, 3, 64) = 576 values. \n","SHAPE BLOCO CONV 5: (1, 0, 1, 1, 128) = 0 values. \n"]}]},{"cell_type":"code","source":["rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","\"\"\"x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\"\"\"\n","\n","#Em paralelo com o x de cima\"\n","\n","\n","lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","print('ConvLSTM2D 1: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","\n","lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","print('ConvLSTM2D 2: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","\n","lstm = MaxPooling3D(pool_size=(2,3,3))(lstm)\n","print('ConvLSTM2D 3: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ajtR51eRq22","executionInfo":{"status":"ok","timestamp":1652152411783,"user_tz":180,"elapsed":388,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"c1e66e37-a2c8-497c-a4c3-56260ba421a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","ConvLSTM2D 1: (1, 2, 7, 7, 32) = 3136 values. \n","ConvLSTM2D 2: (1, 2, 7, 7, 64) = 6272 values. \n","ConvLSTM2D 3: (1, 2, 4, 4, 128) = 4096 values. \n"]}]},{"cell_type":"code","source":["# https://arxiv.org/pdf/1709.06531.pdf\n","# Learning to detect violence videos using convolutional long short-term memory. 2017.\n","# https://github.com/aggression-detect/aggression_detect/blob/eedbaf3ab15595998ea8af1620c237d68318a42f/LSTM_CNN/BuildModel_basic.py\n","rgb = video_tensor\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","print('SHAPE BLOCO CONV 1: {0} = {1} values. '.format(str(rgb.shape), str(rgb.shape[0]*rgb.shape[1]*rgb.shape[2]*rgb.shape[3]*rgb.shape[4])))\n","\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","print('SHAPE MAX 2: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","#####################################################\n","\"\"\"x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 3: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","print('SHAPE BLOCO CONV 4: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","print('SHAPE BLOCO CONV 5: {0} = {1} values. '.format(str(x.shape), str(x.shape[0]*x.shape[1]*x.shape[2]*x.shape[3]*x.shape[4])))\"\"\"\n","\n","#Em paralelo com o x de cima\"\n","\n","# cnn = TimeDistributed(cnn)(input_layer)\n","\n","lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","print('ConvLSTM2D 1: {0} = {1} values. '.format(str(lstm.shape), str(lstm.shape[0]*lstm.shape[1]*lstm.shape[2]*lstm.shape[3]*lstm.shape[4])))\n","\n","\n","#lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","lstm = Flatten()(lstm)\n","print('Flatten 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","dropout = 0.5\n","lstm = BatchNormalization()(lstm)\n","print('BatchNormalization 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dense(1000)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dense(256)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Dense(10)(lstm)\n","print('Dense 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Dropout(dropout)(lstm)\n","print('Dropout 1: {0} = x values. '.format(str(lstm.shape)))\n","\n","lstm = Activation('relu')(lstm)\n","print('Activation: {0} = x values. '.format(str(lstm.shape)))\n","\n","#activation = 'sigmoid'\n","#loss_func = 'binary_crossentropy'\n","\n","\n","#FALTA A ÚLTIMA CAMADA DENSA\n","\n","\n","\n","\"\"\"if classes > 1:\n","    activation = 'softmax'\n","    loss_func = 'categorical_crossentropy'\n","predictions = Dense(classes,  activation=activation)(relu)\n","\n","\n","model = Model(inputs=input_layer, outputs=predictions)\n","optimizer = optimizer_class[0](lr=learning_rate, **optimizer_class[1])\n","model.compile(optimizer=optimizer, loss=loss_func,metrics=['acc'])\n","\n","print(model.summary())\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"I-Fxkhc4eNbD","executionInfo":{"status":"ok","timestamp":1652152413155,"user_tz":180,"elapsed":1380,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"96ff743f-b335-4884-ce46-0a1cd281fced"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SHAPE BLOCO CONV 1: (1, 32, 14, 14, 32) = 200704 values. \n","SHAPE MAX 2: (1, 4, 14, 14, 32) = 25088 values. \n","ConvLSTM2D 1: (1, 4, 14, 14, 256) = 200704 values. \n","Flatten 1: (1, 200704) = x values. \n","BatchNormalization 1: (1, 200704) = x values. \n","Dropout 1: (1, 200704) = x values. \n","Dense 1: (1, 1000) = x values. \n","Activation: (1, 1000) = x values. \n","Dense 1: (1, 256) = x values. \n","Dropout 1: (1, 256) = x values. \n","Activation: (1, 256) = x values. \n","Dense 1: (1, 10) = x values. \n","Dropout 1: (1, 10) = x values. \n","Activation: (1, 10) = x values. \n"]},{"output_type":"execute_result","data":{"text/plain":["\"if classes > 1:\\n    activation = 'softmax'\\n    loss_func = 'categorical_crossentropy'\\npredictions = Dense(classes,  activation=activation)(relu)\\n\\n\\nmodel = Model(inputs=input_layer, outputs=predictions)\\noptimizer = optimizer_class[0](lr=learning_rate, **optimizer_class[1])\\nmodel.compile(optimizer=optimizer, loss=loss_func,metrics=['acc'])\\n\\nprint(model.summary())\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAU2MEuDJpSr","executionInfo":{"status":"ok","timestamp":1652152413156,"user_tz":180,"elapsed":25,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"de59a58b-578c-40d1-eed6-beb62a999025"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 4, 14, 14, 32])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["32*14*14*32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uK1N9NcbJYlT","executionInfo":{"status":"ok","timestamp":1652152413158,"user_tz":180,"elapsed":19,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"719281b1-1698-4bf7-9e43-5077fd7477d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200704"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Início"],"metadata":{"id":"kShteWft-dGB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2b0LosEhvgA0"},"outputs":[],"source":["# Paths base\n","PATH_BASE = '/content/drive/MyDrive/ucf_experiments/'\n","PATH_CICLE = PATH_BASE + 'ciclo_experimental_1/'\n","\n","# Path base de armazenamento dos augmentations\n","PATH_DATA = PATH_CICLE + 'data/'\n","\n","# Dados de treino augmentados\n","#PATH_AUG_BASE = PATH_DATA + 'augmented_train/'\n","# Dados de teste redimensionados (visto que não popdem ser augmentados)\n","#PATH_TEST_RESIZED = PATH_DATA + 'resized_test/'\n","\n","PATH_BLUR_CONVLSTM = PATH_DATA + 'data_blur_convlstm/' #data_blur\n","PATH_BLUR = PATH_DATA + 'data_blur/' #data_blur"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652152418933,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"RlpTDpPZv5dp","outputId":"6d7c4f57-f970-4672-8af4-8125815c70eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/runs/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/runs/  Created \n"]}],"source":["# Create target directory & all intermediate directories if don't exists\n","def create_dir(dirName):\n","  try:\n","      os.makedirs(dirName) \n","      print(dirName)   \n","      print(\"Directory \" , dirName ,  \" Created \")\n","      return dirName\n","  except FileExistsError:\n","      print(\"Directory \" , dirName ,  \" already exists\")  \n","      return dirName\n","\n","\n","PATH_BLUR_CONVLSTM_MODEL = create_dir(PATH_BLUR_CONVLSTM + 'model/')\n","PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS = create_dir(PATH_BLUR_CONVLSTM_MODEL + 'checkpoints/')\n","PATH_TENSORBOARD = create_dir(PATH_BLUR_CONVLSTM_MODEL + 'runs/')"]},{"cell_type":"markdown","metadata":{"id":"26PzXiHKhPGA"},"source":["## Uniform Sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1652152420036,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"a8voaKPMjC_E","outputId":"186e9db3-4a5d-4dba-a0de-d8c43190d7c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/train/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/train/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/train/\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/test/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/test/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/test/\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_train/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_train/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_train/\n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_test/\n","Directory  /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_test/  Created \n","/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/uniform_samples/checkpoints_test/\n"]}],"source":["PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TRAIN = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/train/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TRAIN)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TEST = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/test/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_TEST)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TRAIN = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/checkpoints_train/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TRAIN)\n","\n","PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TEST = create_dir(PATH_BLUR_CONVLSTM + 'uniform_samples/checkpoints_test/')\n","print(PATH_BLUR_CONVLSTM_UNIFORM_SAMPLE_CHECK_TEST)"]},{"cell_type":"code","source":["# Copiando os dados do experimento data_blur para este (data_blur_lstm)\n","# PATH_BLUR -> PATH_BLUR_CONVLSTM\n","\n","source=PATH_BLUR + 'train_uniform_sample_rwf2000.txt'\n","destination=PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt'\n","shutil.copyfile(source, destination)\n","\n","source=PATH_BLUR + 'test_uniform_sample_rwf2000.txt'\n","destination=PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt'\n","shutil.copyfile(source, destination)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"PtRWuFK-B958","executionInfo":{"status":"ok","timestamp":1652152421009,"user_tz":180,"elapsed":416,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"b7463f55-1e96-4962-e153-c98dbb1620db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/test_uniform_sample_rwf2000.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gJVcEa5oROu"},"outputs":[],"source":["train_dataset = pd.read_csv(PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', sep=';', names=['video_path', 'label', 'new_path'])\n","test_dataset = pd.read_csv(PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt', sep=';', names=['video_path', 'label', 'new_path'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TuJoG22A94aS","executionInfo":{"status":"ok","timestamp":1652152454433,"user_tz":180,"elapsed":474,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"18ab118a-a6df-4b18-ea3a-5098ee6ca942"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"train_dataset = train_dataset.loc[\\n                                  (train_dataset.video_path.str.contains('_x264_') |\\n                                   ~train_dataset.video_path.str.contains('_x264-')) & \\n                                  (train_dataset.video_path.str.contains('resized'))]\\n\\ntest_dataset = test_dataset.loc[\\n                                (test_dataset.video_path.str.contains('_x264_') | \\n                                 ~test_dataset.video_path.str.contains('_x264-')) &\\n                                (test_dataset.video_path.str.contains('resized'))]\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["\"\"\"train_dataset = train_dataset.loc[\n","                                  (train_dataset.video_path.str.contains('_x264_') |\n","                                   ~train_dataset.video_path.str.contains('_x264-')) & \n","                                  (train_dataset.video_path.str.contains('resized'))]\n","\n","test_dataset = test_dataset.loc[\n","                                (test_dataset.video_path.str.contains('_x264_') | \n","                                 ~test_dataset.video_path.str.contains('_x264-')) &\n","                                (test_dataset.video_path.str.contains('resized'))]\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1652152454782,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"6Cs2L1m3-nJd","outputId":"23d82014-2f9a-4f16-82ca-399faafffd2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400, 3)"]},"metadata":{},"execution_count":17}],"source":["test_dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1652152457118,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"},"user_tz":180},"id":"-hA_psPy-ljN","outputId":"d5405df9-03a7-45c3-fdb5-78402faeccf4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1600, 3)"]},"metadata":{},"execution_count":18}],"source":["train_dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RR3ZjfOE44wL"},"outputs":[],"source":["\"\"\"train_dataset.to_csv(PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\n","test_dataset.to_csv(PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt', index=False, header=None, sep=';')\"\"\""]},{"cell_type":"code","source":["train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"9sDRF1h29fMi","executionInfo":{"status":"ok","timestamp":1652152467372,"user_tz":180,"elapsed":366,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"4b7931bf-d251-4beb-cd17-2bc822cc7385"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             video_path  label  new_path\n","0     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","1     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","2     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","3     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","4     /content/drive/MyDrive/ucf_experiments/ciclo_e...      1       NaN\n","...                                                 ...    ...       ...\n","1595  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1596  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1597  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1598  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","1599  /content/drive/MyDrive/ucf_experiments/ciclo_e...      0       NaN\n","\n","[1600 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-5b22577f-06fb-431a-b1be-c8e410975993\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_path</th>\n","      <th>label</th>\n","      <th>new_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1595</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1596</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1597</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1598</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1599</th>\n","      <td>/content/drive/MyDrive/ucf_experiments/ciclo_e...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1600 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b22577f-06fb-431a-b1be-c8e410975993')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5b22577f-06fb-431a-b1be-c8e410975993 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5b22577f-06fb-431a-b1be-c8e410975993');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHLR25qXoYXc"},"outputs":[],"source":["max_batch_size = 5\n","\n","train_dataset_list = train_dataset.new_path.tolist()\n","train_label_list = train_dataset.label.tolist()\n","\n","test_dataset_list = test_dataset.new_path.tolist()\n","test_label_list = test_dataset.label.tolist()\n","NUM_WORKERS=4\n","EPOCHS=60\n","BATCH_SIZE=8\n","\n","N_CLASSES = 2\n","IMSIZE = (224, 224)\n","SequenceLength = 64\n","\n","STEPS_PER_EPOCH = int(len(train_dataset_list) / BATCH_SIZE)\n","VAL_STEPS_PER_EPOCH = int(len(test_dataset_list) / BATCH_SIZE)\n","\n","shapes = ((BATCH_SIZE, SequenceLength, IMSIZE[0], IMSIZE[1], 3), (BATCH_SIZE, N_CLASSES))\n","dtypes = (tf.float32, tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"xZPVeX2wSUXw"},"source":["# Treino"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPO9em86MYfW"},"outputs":[],"source":["from keras.models import Sequential, Input, Model\n","from keras.models import load_model\n","from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n","from keras.regularizers import l2\n","from keras.layers.core import Lambda\n","from keras.layers.core import Lambda\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras import mixed_precision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxp-7Jn8tglv"},"outputs":[],"source":["from tensorflow.keras import mixed_precision\n","\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_global_policy(policy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7lThedsDCB3"},"outputs":[],"source":["# def load_pretrained_model():\n","#   sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","#   model = load_model('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/keras_model.h5')\n","\n","#   model.compile(optimizer=sgd,\n","#                 loss='categorical_crossentropy',\n","#                 metrics=['accuracy'])\n","  \n","#   return model"]},{"cell_type":"markdown","source":["## Model 0"],"metadata":{"id":"x9NDZQxFLzM2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"imqOkNqLMYdQ"},"outputs":[],"source":["def create_model(continue_training=False, last_checkpoint=0):\n","  metrics=[\n","    tf.keras.metrics.Precision(),\n","    tf.keras.metrics.CategoricalAccuracy(),\n","    tf.keras.metrics.Recall(),\n","    tf.keras.metrics.AUC()\n","  ]\n","\n","  inputs = Input(shape=(SequenceLength, IMSIZE[0], IMSIZE[1], 3))\n","\n","  #####################################################\n","  rgb = inputs\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","\n","  ##############################################\n","  ##############################################\n","\n","  #https://github.com/satyachaurasia/Violence-Detection-using-ConvLSTM/blob/master/ViolentModel.py\n","  #file:///C:/Users/jayne/Documents/Mestrado/Artigos%20coletados/A%20Frame-Based%20Feature%20Model%20for%20Violence%20Detection%20from%20Surveillance%20Cameras%20Using%20ConvLSTM%20Network.pdf\n","  #https://github.com/CankayaUniversity/ceng-407-408-2020-2021-Violent-Activity-Detection-from-Videos/blob/main/model.ipynb\n","  #https://www.programcreek.com/python/example/120287/keras.layers.ConvLSTM2D\n","\n","  #3 blocos ConvLSTM + Fully conected\n","\n","  lstm = ConvLSTM2D(filters=32, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(rgb)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","\n","  #lstm = Dropout(0.4)(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=64, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(lstm)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","  lstm = BatchNormalization()(lstm)\n","\n","  lstm = ConvLSTM2D(filters=128, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(lstm)\n","  lstm = MaxPooling3D(pool_size=(2,2,2))(lstm)\n","\n","  lstm = BatchNormalization()(lstm)\n","\n","  ##############################################\n","  ##############################################\n","\n","\n","  #Model \n","  #lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(inputs)\n","\n","\n","  ##################################################### Fusion and Pooling\n","  #x = Multiply()([rgb, lstm])\n","  x = MaxPooling3D(pool_size=(8,1,1))(lstm)\n","\n","  ##################################################### Merging Block\n","\n","  \"\"\"lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  lstm = Flatten()(lstm)\n","  dropout = 0.5\n","  lstm = BatchNormalization()(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Dense(1000)(lstm)\n","  lstm = Activation('relu')(lstm)\n","  lstm = Dense(256)(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Activation('relu')(lstm)\"\"\"\n","\n","\n","  \n","  \"\"\"x = Conv3D(\n","      64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","  x = Conv3D(\n","      64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","  x = Conv3D(\n","      128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = Conv3D(\n","      128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","  x = MaxPooling3D(pool_size=(2,3,3))(x)\"\"\"\n","\n","  #####################################################\n","  x = Flatten()(x)\n","\n","\n","  x = Dense(128,activation='relu')(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(32, activation='relu')(x)\n","  pred = Dense(N_CLASSES, activation='softmax', dtype='float32')(x)\n","  model = Model(inputs=inputs, outputs=pred)\n","\n","  sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n","\n","  return model"]},{"cell_type":"markdown","source":["## Model 1"],"metadata":{"id":"dZNS-1DHL8A5"}},{"cell_type":"code","source":["def create_model1(continue_training=False, last_checkpoint=0):\n","  metrics=[\n","    tf.keras.metrics.Precision(),\n","    tf.keras.metrics.CategoricalAccuracy(),\n","    tf.keras.metrics.Recall(),\n","    tf.keras.metrics.AUC()\n","  ]\n","\n","  inputs = Input(shape=(SequenceLength, IMSIZE[0], IMSIZE[1], 3))\n","\n","  #####################################################\n","  rgb = inputs\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","  rgb = Conv3D(\n","      32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = Conv3D(\n","      32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","  rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","\n","  #####################################################\n","  x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","\n","\n","  #####################################################\n","\n","  # cnn = TimeDistributed(cnn)(input_layer)\n","  lstm = ConvLSTM2D(filters=256, kernel_size=(3,3), strides=1, padding = \"same\", return_sequences=True, activation='relu')(x)\n","  lstm = Flatten()(lstm)\n","  dropout = 0.5\n","  lstm = BatchNormalization()(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Dense(1000)(lstm)\n","  lstm = Activation('relu')(lstm)\n","  lstm = Dense(256)(lstm)\n","  lstm = Dropout(dropout)(lstm)\n","  lstm = Activation('relu')(lstm)\n","\n","\n","  #####################################################\n","  x = Flatten()(lstm)\n","  x = Dense(128,activation='relu')(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(32, activation='relu')(x)\n","  pred = Dense(2, activation='softmax')(x)\n","  model = Model(inputs=inputs, outputs=pred)\n","\n","  sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n","\n","  return model\n","\n","\n","\"\"\"\n","Node: 'model_2/conv3d_47/Conv3D'\n","2 root error(s) found.\n","  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,150,224,224,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[{{node model_2/conv3d_47/Conv3D}}]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n","\n","\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_860/_181]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n","\n","  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,150,224,224,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[{{node model_2/conv3d_47/Conv3D}}]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n","\n","0 successful operations.\n","0 derived errors ignored. [Op:__inference_train_function_19979]\n","\"\"\""],"metadata":{"id":"PUCc9Ru-xg0d","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1652152479718,"user_tz":180,"elapsed":6,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"dee65c25-4df4-4250-d1ca-3b4ec504ce8b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nNode: 'model_2/conv3d_47/Conv3D'\\n2 root error(s) found.\\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,150,224,224,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\\n\\t [[{{node model_2/conv3d_47/Conv3D}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n\\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_860/_181]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[8,150,224,224,16] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\\n\\t [[{{node model_2/conv3d_47/Conv3D}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n\\n0 successful operations.\\n0 derived errors ignored. [Op:__inference_train_function_19979]\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xX2Uu0gDfHOp"},"outputs":[],"source":["import tensorflow.keras as keras\n","from tensorflow.keras.utils import Sequence\n","from keras.utils import np_utils\n","import mediapy as media\n","\n","class DataGenerator(Sequence):\n","    \"\"\"Data Generator inherited from keras.utils.Sequence\n","    Args: \n","        directory: the path of data set, and each sub-folder will be assigned to one class\n","        batch_size: the number of data points in each batch\n","        shuffle: whether to shuffle the data per epoch\n","    Note:\n","        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n","    \"\"\"\n","    def __init__(self, input_file, batch_size=1, shuffle=True, data_augmentation=True, uniform_sample=False):\n","        # Initialize the params\n","        self.batch_size = batch_size\n","        self.input_file = input_file\n","        self.classes = 2\n","        self.shuffle = shuffle\n","        self.data_aug = data_augmentation\n","        self.uniform_sample = uniform_sample\n","        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n","        self.X_path, self.Y_dict = self.search_data() \n","        # Print basic statistics information\n","        self.print_stats()\n","        return None\n","        \n","    def search_data_v2(self):\n","        X_path = []\n","        Y_dict = {}\n","        \"\"\"one_hots = np_utils.to_categorical(range(self.classes))\n","\n","        with open(self.input_file, 'r') as data_file:\n","           for line in data_file:\n","              line = line.rstrip('\\n')\n","              path = line[:-2]\n","\n","              label = int(line[-1:])\n","              X_path.append(path)\n","              Y_dict[path] = one_hots[label]\"\"\"\n","\n","        # # list all kinds of sub-folders\n","        # self.dirs = sorted(os.listdir(self.directory))\n","        # one_hots = np_utils.to_categorical(range(len(self.dirs)))\n","        # for i,folder in enumerate(self.dirs):\n","        #     folder_path = os.path.join(self.directory,folder)\n","        #     for file in os.listdir(folder_path):\n","        #         file_path = os.path.join(folder_path,file)\n","        #         # append the each file path, and keep its label  \n","        #         X_path.append(file_path)\n","        #         Y_dict[file_path] = one_hots[i]\n","\n","        df_videos = pd.read_csv(self.input_file, header=None, sep=';', names=['video_path', 'label', 'frames32'])\n","        df_videos_filtered = df_videos.loc[df_videos.frames32 == 0]\n","\n","        X_path = df_videos_filtered[['video_path', 'label']].video_path.to_list()\n","        Y_dict = pd.get_dummies(df_videos_filtered[['video_path', 'label']], columns=['label']).set_index('video_path').T.to_dict(orient=\"list\")\n","\n","        return X_path, Y_dict\n","\n","    def search_data(self):\n","        X_path = []\n","        Y_dict = {}\n","        one_hots = np_utils.to_categorical(range(self.classes))\n","\n","        with open(self.input_file, 'r') as data_file:\n","           for line in data_file:\n","              line = line.rstrip('\\n').split(';')\n","              path = line[0]\n","\n","              label = int(line[1])\n","              X_path.append(path)\n","              Y_dict[path] = one_hots[label]\n","\n","        return X_path, Y_dict\n","    \n","    def print_stats(self):\n","        # calculate basic information\n","        self.n_files = len(self.X_path)\n","        self.n_classes = self.classes\n","        self.indexes = np.arange(len(self.X_path))\n","        np.random.shuffle(self.indexes)\n","        # Output states\n","        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n","        for i,label in enumerate(range(self.classes)):\n","            print('%10s : '%(label),i)\n","        return None\n","    \n","    def __len__(self):\n","        # calculate the iterations of each epoch\n","        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n","        return int(steps_per_epoch)\n","\n","    def __getitem__(self, index):\n","        \"\"\"Get the data of each batch\n","        \"\"\"\n","        # get the indexs of each batch\n","        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # using batch_indexs to get path of current batch\n","        batch_path = [self.X_path[k] for k in batch_indexs]\n","        # get batch data\n","        batch_x, batch_y = self.data_generation(batch_path)\n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        # shuffle the data at each end of epoch\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def data_generation(self, batch_path):\n","        # load data into memory, you can change the np.load to any method you want\n","        batch_x = [self.load_data(x) for x in batch_path]\n","        batch_y = [self.Y_dict[x] for x in batch_path]\n","        # transfer the data format and take one-hot coding for labels\n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","        return batch_x, batch_y\n","      \n","    def normalize(self, data):\n","        mean = np.mean(data)\n","        std = np.std(data)\n","        return (data-mean) / std\n","    \n","    def random_flip(self, video, prob):\n","        s = np.random.rand()\n","        if s < prob:\n","            video = np.flip(m=video, axis=2)\n","        return video    \n","    \n","    def uniform_sampling(self, video, target_frames=64):\n","        # get total frames of input video and calculate sampling interval \n","        len_frames = int(len(video))\n","        interval = int(np.ceil(len_frames/target_frames))\n","        # init empty list for sampled video and \n","        sampled_video = []\n","        for i in range(0,len_frames,interval):\n","            sampled_video.append(video[i])     \n","        # calculate numer of padded frames and fix it \n","        num_pad = target_frames - len(sampled_video)\n","        if num_pad>0:\n","            padding = [video[i] for i in range(-num_pad,0)]\n","            sampled_video += padding     \n","        # get sampled video\n","\n","        #sampled_video = tf.image.resize(sampled_video, [224,224])\n","        return np.array(sampled_video, dtype=np.float32)\n","    \n","    def dynamic_crop(self, video):\n","        # extract layer of optical flow from video\n","        opt_flows = video[...,3]\n","        # sum of optical flow magnitude of individual frame\n","        magnitude = np.sum(opt_flows, axis=0)\n","        # filter slight noise by threshold \n","        thresh = np.mean(magnitude)\n","        magnitude[magnitude<thresh] = 0\n","        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n","        x_pdf = np.sum(magnitude, axis=1) + 0.001\n","        y_pdf = np.sum(magnitude, axis=0) + 0.001\n","        # normalize PDF of x and y so that the sum of probs = 1\n","        x_pdf /= np.sum(x_pdf)\n","        y_pdf /= np.sum(y_pdf)\n","        # randomly choose some candidates for x and y \n","        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n","        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n","        # get the mean of x and y coordinates for better robustness\n","        x = int(np.mean(x_points))\n","        y = int(np.mean(y_points))\n","        # avoid to beyond boundaries of array\n","        x = max(56,min(x,167))\n","        y = max(56,min(y,167))\n","        # get cropped video \n","        return video[:,x-56:x+56,y-56:y+56,:]  \n","    \n","    def color_jitter(self,video):\n","        # range of s-component: 0-1\n","        # range of v component: 0-255\n","        s_jitter = np.random.uniform(-0.2,0.2)\n","        v_jitter = np.random.uniform(-30,30)\n","        for i in range(len(video)):\n","            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n","            s = hsv[...,1] + s_jitter\n","            v = hsv[...,2] + v_jitter\n","            s[s<0] = 0\n","            s[s>1] = 1\n","            v[v<0] = 0\n","            v[v>255] = 255\n","            hsv[...,1] = s\n","            hsv[...,2] = v\n","            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n","        return video\n","        \n","    def load_data(self, path):\n","        data = media.read_video(path)[...,:3]\n","        data = np.float32(data)\n","        # sampling 64 frames uniformly from the entire video\n","\n","        if self.uniform_sample:\n","          data = self.uniform_sampling(video=data, target_frames=64)\n","        else:\n","          data = np.array(data, dtype=np.float32)\n","\n","        # whether to utilize the data augmentation\n","        if  self.data_aug:\n","            data = self.color_jitter(data)\n","            data = self.random_flip(data, prob=0.5)\n","        # normalize\n","\n","        data = self.normalize(data)\n","        return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixYRmjWoMsBo"},"outputs":[],"source":["import keras.backend as K\n","from keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch):\n","    # Every 10 epochs, the learning rate is reduced to 1/10 of the original\n","    if epoch % 10 == 0 and epoch != 0:\n","        lr = K.get_value(model.optimizer.lr)\n","        K.set_value(model.optimizer.lr, lr * 0.5)\n","    return K.get_value(model.optimizer.lr)"]},{"cell_type":"code","source":["model = create_model()\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPB5-fvqYfA3","executionInfo":{"status":"ok","timestamp":1652152483219,"user_tz":180,"elapsed":1008,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"29058d8a-09c2-4df4-8036-29c8f9e5b3ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 64, 224, 224, 3)  0         \n","                             ]                                   \n","                                                                 \n"," conv3d_30 (Conv3D)          (None, 64, 224, 224, 16)  448       \n","                                                                 \n"," conv3d_31 (Conv3D)          (None, 64, 224, 224, 16)  784       \n","                                                                 \n"," max_pooling3d_21 (MaxPoolin  (None, 64, 112, 112, 16)  0        \n"," g3D)                                                            \n","                                                                 \n"," conv3d_32 (Conv3D)          (None, 64, 112, 112, 16)  2320      \n","                                                                 \n"," conv3d_33 (Conv3D)          (None, 64, 112, 112, 16)  784       \n","                                                                 \n"," max_pooling3d_22 (MaxPoolin  (None, 64, 56, 56, 16)   0         \n"," g3D)                                                            \n","                                                                 \n"," conv3d_34 (Conv3D)          (None, 64, 56, 56, 32)    4640      \n","                                                                 \n"," conv3d_35 (Conv3D)          (None, 64, 56, 56, 32)    3104      \n","                                                                 \n"," max_pooling3d_23 (MaxPoolin  (None, 64, 28, 28, 32)   0         \n"," g3D)                                                            \n","                                                                 \n"," conv3d_36 (Conv3D)          (None, 64, 28, 28, 32)    9248      \n","                                                                 \n"," conv3d_37 (Conv3D)          (None, 64, 28, 28, 32)    3104      \n","                                                                 \n"," max_pooling3d_24 (MaxPoolin  (None, 64, 14, 14, 32)   0         \n"," g3D)                                                            \n","                                                                 \n"," conv_lstm2d_8 (ConvLSTM2D)  (None, 64, 14, 14, 32)    73856     \n","                                                                 \n"," max_pooling3d_25 (MaxPoolin  (None, 32, 7, 7, 32)     0         \n"," g3D)                                                            \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 32, 7, 7, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv_lstm2d_9 (ConvLSTM2D)  (None, 32, 7, 7, 64)      221440    \n","                                                                 \n"," max_pooling3d_26 (MaxPoolin  (None, 16, 3, 3, 64)     0         \n"," g3D)                                                            \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 16, 3, 3, 64)     256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv_lstm2d_10 (ConvLSTM2D)  (None, 16, 3, 3, 128)    885248    \n","                                                                 \n"," max_pooling3d_27 (MaxPoolin  (None, 8, 1, 1, 128)     0         \n"," g3D)                                                            \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 8, 1, 1, 128)     512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling3d_28 (MaxPoolin  (None, 1, 1, 1, 128)     0         \n"," g3D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 1,226,578\n","Trainable params: 1,226,130\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["train_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train_uniform_sample_rwf2000.txt', \n","                            batch_size=BATCH_SIZE, \n","                            data_augmentation=True,\n","                            uniform_sample=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KR2MR48v46qI","executionInfo":{"status":"ok","timestamp":1652152496123,"user_tz":180,"elapsed":393,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"1772fc42-9610-4d07-97d0-bc6409289783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n"]}]},{"cell_type":"code","source":["batch = next(iter(train_generator))"],"metadata":{"id":"yCqRXKnJ49IJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch[0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqT-lI2U5bYY","executionInfo":{"status":"ok","timestamp":1652152601065,"user_tz":180,"elapsed":15,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"227a9df9-ff8f-4215-ae01-eca0f60ee2fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 224, 224, 3)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["with tf.device('/gpu:0'):  \n","  # train_pipe = video_pipe(\n","  #     file_list=train_dataset_list,\n","  #     label_list=train_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # train_generator = dali_tf.DALIDataset(\n","  #       pipeline=train_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0\n","  # )\n","\n","  # test_pipe = video_pipe(\n","  #     file_list=test_dataset_list,\n","  #     label_list=test_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # test_generator = dali_tf.DALIDataset(\n","  #       pipeline=test_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0 \n","  # )\n","\n","  train_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/train_uniform_sample_rwf2000.txt', \n","                              batch_size=BATCH_SIZE, \n","                              data_augmentation=True,\n","                              uniform_sample=False)\n","    \n","  val_generator = DataGenerator(input_file='/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur/test_uniform_sample_rwf2000.txt',\n","                                batch_size=BATCH_SIZE, \n","                                data_augmentation=False,\n","                                uniform_sample=False)\n","\n","  \n","  model = create_model()\n","\n","  reduce_lr = LearningRateScheduler(scheduler)\n","  tb_callback = tf.keras.callbacks.TensorBoard(PATH_TENSORBOARD, update_freq=1)\n","  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS + \"model.{epoch:02d}.h5\",\n","                                                  save_weights_only=False,\n","                                                  verbose=1)\n","  \n","  callbacks_list = [reduce_lr, tb_callback, cp_callback]\n","  \n","  hist = model.fit(\n","    train_generator, \n","    validation_data=val_generator,\n","    validation_steps=VAL_STEPS_PER_EPOCH,\n","    callbacks=callbacks_list,\n","    workers=16,\n","    max_queue_size=8, \n","    verbose=1, \n","    epochs=EPOCHS,\n","    steps_per_epoch=STEPS_PER_EPOCH,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SfhofjbBiwKO","executionInfo":{"status":"error","timestamp":1652171211862,"user_tz":180,"elapsed":18606286,"user":{"displayName":"Jayne Morais","userId":"16712906180843592229"}},"outputId":"7dec0c38-ca7c-4553-8d6b-77417b5181d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n","Found 400 files belonging to 2 classes.\n","         0 :  0\n","         1 :  1\n","Epoch 1/60\n","200/200 [==============================] - ETA: 0s - loss: 0.9972 - precision_1: 0.5006 - categorical_accuracy: 0.5006 - recall_1: 0.5006 - auc_1: 0.5121\n","Epoch 1: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.01.h5\n","200/200 [==============================] - 754s 4s/step - loss: 0.9972 - precision_1: 0.5006 - categorical_accuracy: 0.5006 - recall_1: 0.5006 - auc_1: 0.5121 - val_loss: 0.6945 - val_precision_1: 0.5275 - val_categorical_accuracy: 0.5275 - val_recall_1: 0.5275 - val_auc_1: 0.5122 - lr: 0.0100\n","Epoch 2/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0076 - precision_1: 0.4944 - categorical_accuracy: 0.4944 - recall_1: 0.4944 - auc_1: 0.5025\n","Epoch 2: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.02.h5\n","200/200 [==============================] - 797s 4s/step - loss: 1.0076 - precision_1: 0.4944 - categorical_accuracy: 0.4944 - recall_1: 0.4944 - auc_1: 0.5025 - val_loss: 0.7351 - val_precision_1: 0.4900 - val_categorical_accuracy: 0.4900 - val_recall_1: 0.4900 - val_auc_1: 0.5079 - lr: 0.0100\n","Epoch 3/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0423 - precision_1: 0.4850 - categorical_accuracy: 0.4850 - recall_1: 0.4850 - auc_1: 0.4852\n","Epoch 3: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.03.h5\n","200/200 [==============================] - 827s 4s/step - loss: 1.0423 - precision_1: 0.4850 - categorical_accuracy: 0.4850 - recall_1: 0.4850 - auc_1: 0.4852 - val_loss: 0.7905 - val_precision_1: 0.4800 - val_categorical_accuracy: 0.4800 - val_recall_1: 0.4800 - val_auc_1: 0.4996 - lr: 0.0100\n","Epoch 4/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0433 - precision_1: 0.5050 - categorical_accuracy: 0.5050 - recall_1: 0.5050 - auc_1: 0.5015\n","Epoch 4: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.04.h5\n","200/200 [==============================] - 861s 4s/step - loss: 1.0433 - precision_1: 0.5050 - categorical_accuracy: 0.5050 - recall_1: 0.5050 - auc_1: 0.5015 - val_loss: 0.7824 - val_precision_1: 0.4725 - val_categorical_accuracy: 0.4725 - val_recall_1: 0.4725 - val_auc_1: 0.5034 - lr: 0.0100\n","Epoch 5/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0079 - precision_1: 0.4913 - categorical_accuracy: 0.4913 - recall_1: 0.4913 - auc_1: 0.4987\n","Epoch 5: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.05.h5\n","200/200 [==============================] - 901s 4s/step - loss: 1.0079 - precision_1: 0.4913 - categorical_accuracy: 0.4913 - recall_1: 0.4913 - auc_1: 0.4987 - val_loss: 0.7851 - val_precision_1: 0.4775 - val_categorical_accuracy: 0.4775 - val_recall_1: 0.4775 - val_auc_1: 0.4990 - lr: 0.0100\n","Epoch 6/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0135 - precision_1: 0.5044 - categorical_accuracy: 0.5044 - recall_1: 0.5044 - auc_1: 0.5097\n","Epoch 6: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.06.h5\n","200/200 [==============================] - 942s 5s/step - loss: 1.0135 - precision_1: 0.5044 - categorical_accuracy: 0.5044 - recall_1: 0.5044 - auc_1: 0.5097 - val_loss: 0.8023 - val_precision_1: 0.4850 - val_categorical_accuracy: 0.4850 - val_recall_1: 0.4850 - val_auc_1: 0.5090 - lr: 0.0100\n","Epoch 7/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0419 - precision_1: 0.4963 - categorical_accuracy: 0.4963 - recall_1: 0.4963 - auc_1: 0.5045\n","Epoch 7: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.07.h5\n","200/200 [==============================] - 960s 5s/step - loss: 1.0419 - precision_1: 0.4963 - categorical_accuracy: 0.4963 - recall_1: 0.4963 - auc_1: 0.5045 - val_loss: 0.8042 - val_precision_1: 0.4725 - val_categorical_accuracy: 0.4725 - val_recall_1: 0.4725 - val_auc_1: 0.4953 - lr: 0.0100\n","Epoch 8/60\n","200/200 [==============================] - ETA: 0s - loss: 0.9899 - precision_1: 0.5169 - categorical_accuracy: 0.5169 - recall_1: 0.5169 - auc_1: 0.5215\n","Epoch 8: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.08.h5\n","200/200 [==============================] - 994s 5s/step - loss: 0.9899 - precision_1: 0.5169 - categorical_accuracy: 0.5169 - recall_1: 0.5169 - auc_1: 0.5215 - val_loss: 0.7801 - val_precision_1: 0.4700 - val_categorical_accuracy: 0.4700 - val_recall_1: 0.4700 - val_auc_1: 0.4957 - lr: 0.0100\n","Epoch 9/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0473 - precision_1: 0.4875 - categorical_accuracy: 0.4875 - recall_1: 0.4875 - auc_1: 0.4943\n","Epoch 9: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.09.h5\n","200/200 [==============================] - 1003s 5s/step - loss: 1.0473 - precision_1: 0.4875 - categorical_accuracy: 0.4875 - recall_1: 0.4875 - auc_1: 0.4943 - val_loss: 0.8010 - val_precision_1: 0.4675 - val_categorical_accuracy: 0.4675 - val_recall_1: 0.4675 - val_auc_1: 0.5038 - lr: 0.0100\n","Epoch 10/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0207 - precision_1: 0.4963 - categorical_accuracy: 0.4963 - recall_1: 0.4963 - auc_1: 0.4963\n","Epoch 10: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.10.h5\n","200/200 [==============================] - 1025s 5s/step - loss: 1.0207 - precision_1: 0.4963 - categorical_accuracy: 0.4963 - recall_1: 0.4963 - auc_1: 0.4963 - val_loss: 0.8173 - val_precision_1: 0.4900 - val_categorical_accuracy: 0.4900 - val_recall_1: 0.4900 - val_auc_1: 0.5016 - lr: 0.0100\n","Epoch 11/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0057 - precision_1: 0.5088 - categorical_accuracy: 0.5088 - recall_1: 0.5088 - auc_1: 0.5097\n","Epoch 11: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.11.h5\n","200/200 [==============================] - 1079s 5s/step - loss: 1.0057 - precision_1: 0.5088 - categorical_accuracy: 0.5088 - recall_1: 0.5088 - auc_1: 0.5097 - val_loss: 0.8046 - val_precision_1: 0.4775 - val_categorical_accuracy: 0.4775 - val_recall_1: 0.4775 - val_auc_1: 0.5027 - lr: 0.0050\n","Epoch 12/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0019 - precision_1: 0.5056 - categorical_accuracy: 0.5056 - recall_1: 0.5056 - auc_1: 0.5116\n","Epoch 12: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.12.h5\n","200/200 [==============================] - 1039s 5s/step - loss: 1.0019 - precision_1: 0.5056 - categorical_accuracy: 0.5056 - recall_1: 0.5056 - auc_1: 0.5116 - val_loss: 0.7768 - val_precision_1: 0.4575 - val_categorical_accuracy: 0.4575 - val_recall_1: 0.4575 - val_auc_1: 0.4950 - lr: 0.0050\n","Epoch 13/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0332 - precision_1: 0.4988 - categorical_accuracy: 0.4988 - recall_1: 0.4988 - auc_1: 0.4960\n","Epoch 13: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.13.h5\n","200/200 [==============================] - 1073s 5s/step - loss: 1.0332 - precision_1: 0.4988 - categorical_accuracy: 0.4988 - recall_1: 0.4988 - auc_1: 0.4960 - val_loss: 0.7983 - val_precision_1: 0.4650 - val_categorical_accuracy: 0.4650 - val_recall_1: 0.4650 - val_auc_1: 0.4982 - lr: 0.0050\n","Epoch 14/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0444 - precision_1: 0.5025 - categorical_accuracy: 0.5025 - recall_1: 0.5025 - auc_1: 0.4993\n","Epoch 14: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.14.h5\n","200/200 [==============================] - 1093s 5s/step - loss: 1.0444 - precision_1: 0.5025 - categorical_accuracy: 0.5025 - recall_1: 0.5025 - auc_1: 0.4993 - val_loss: 0.8342 - val_precision_1: 0.4825 - val_categorical_accuracy: 0.4825 - val_recall_1: 0.4825 - val_auc_1: 0.4987 - lr: 0.0050\n","Epoch 15/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0031 - precision_1: 0.5025 - categorical_accuracy: 0.5025 - recall_1: 0.5025 - auc_1: 0.5013\n","Epoch 15: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.15.h5\n","200/200 [==============================] - 1103s 5s/step - loss: 1.0031 - precision_1: 0.5025 - categorical_accuracy: 0.5025 - recall_1: 0.5025 - auc_1: 0.5013 - val_loss: 0.7976 - val_precision_1: 0.4625 - val_categorical_accuracy: 0.4625 - val_recall_1: 0.4625 - val_auc_1: 0.4962 - lr: 0.0050\n","Epoch 16/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0629 - precision_1: 0.4938 - categorical_accuracy: 0.4938 - recall_1: 0.4938 - auc_1: 0.4824\n","Epoch 16: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.16.h5\n","200/200 [==============================] - 1110s 5s/step - loss: 1.0629 - precision_1: 0.4938 - categorical_accuracy: 0.4938 - recall_1: 0.4938 - auc_1: 0.4824 - val_loss: 0.7973 - val_precision_1: 0.4750 - val_categorical_accuracy: 0.4750 - val_recall_1: 0.4750 - val_auc_1: 0.4998 - lr: 0.0050\n","Epoch 17/60\n","200/200 [==============================] - ETA: 0s - loss: 0.9871 - precision_1: 0.5288 - categorical_accuracy: 0.5288 - recall_1: 0.5288 - auc_1: 0.5235\n","Epoch 17: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.17.h5\n","200/200 [==============================] - 1123s 5s/step - loss: 0.9871 - precision_1: 0.5288 - categorical_accuracy: 0.5288 - recall_1: 0.5288 - auc_1: 0.5235 - val_loss: 0.7936 - val_precision_1: 0.4825 - val_categorical_accuracy: 0.4825 - val_recall_1: 0.4825 - val_auc_1: 0.5019 - lr: 0.0050\n","Epoch 18/60\n","200/200 [==============================] - ETA: 0s - loss: 1.0088 - precision_1: 0.4931 - categorical_accuracy: 0.4931 - recall_1: 0.4931 - auc_1: 0.5095\n","Epoch 18: saving model to /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_blur_convlstm/model/checkpoints/model.18.h5\n","200/200 [==============================] - 1197s 6s/step - loss: 1.0088 - precision_1: 0.4931 - categorical_accuracy: 0.4931 - recall_1: 0.4931 - auc_1: 0.5095 - val_loss: 0.7876 - val_precision_1: 0.4775 - val_categorical_accuracy: 0.4775 - val_recall_1: 0.4775 - val_auc_1: 0.5067 - lr: 0.0050\n","Epoch 19/60\n"," 91/200 [============>.................] - ETA: 8:25 - loss: 1.0584 - precision_1: 0.4945 - categorical_accuracy: 0.4945 - recall_1: 0.4945 - auc_1: 0.4894"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d0f824c31852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     steps_per_epoch=STEPS_PER_EPOCH,)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-32-d0f824c31852>\", line 62, in <module>\n      steps_per_epoch=STEPS_PER_EPOCH,)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 1414, in update_state\n      sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 605, in update_confusion_matrix_variables\n      message='predictions must be >= 0'),\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-32-d0f824c31852>\", line 62, in <module>\n      steps_per_epoch=STEPS_PER_EPOCH,)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 1414, in update_state\n      sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 605, in update_confusion_matrix_variables\n      message='predictions must be >= 0'),\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_1/dense_8/Softmax:0) = ] [[nan nan][nan...]...] [y (Cast_2/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]]\n\t [[assert_less_equal_2/Assert/AssertGuard/pivot_f/_2384/_531]]\n  (1) INVALID_ARGUMENT:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_1/dense_8/Softmax:0) = ] [[nan nan][nan...]...] [y (Cast_2/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_19983]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBZQnYw1MsGY"},"outputs":[],"source":["with tf.device('/gpu:0'):  \n","  # train_pipe = video_pipe(\n","  #     file_list=train_dataset_list,\n","  #     label_list=train_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # train_generator = dali_tf.DALIDataset(\n","  #       pipeline=train_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0\n","  # )\n","\n","  # test_pipe = video_pipe(\n","  #     file_list=test_dataset_list,\n","  #     label_list=test_label_list,\n","  #     batch_size=BATCH_SIZE, \n","  #     num_threads=4\n","  # )\n","\n","  # test_generator = dali_tf.DALIDataset(\n","  #       pipeline=test_pipe,\n","  #       batch_size=BATCH_SIZE,\n","  #       output_shapes=shapes,\n","  #       output_dtypes=dtypes,\n","  #       device_id=0 \n","  # )\n","\n","  train_generator = DataGenerator(input_file=PATH_BLUR_CONVLSTM + 'train_uniform_sample_rwf2000.txt', \n","                              batch_size=BATCH_SIZE, \n","                              data_augmentation=True,\n","                              uniform_sample=False)\n","    \n","  val_generator = DataGenerator(input_file=PATH_BLUR_CONVLSTM + 'test_uniform_sample_rwf2000.txt',\n","                                batch_size=BATCH_SIZE, \n","                                data_augmentation=False,\n","                                uniform_sample=False)\n","\n","  \n","  model = create_model()\n","\n","  reduce_lr = LearningRateScheduler(scheduler)\n","  tb_callback = tf.keras.callbacks.TensorBoard(PATH_TENSORBOARD, update_freq=1)\n","  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=PATH_BLUR_CONVLSTM_MODEL_CHECKPOINTS + \"model.{epoch:02d}.h5\",\n","                                                  save_weights_only=False,\n","                                                  verbose=1)\n","  \n","  callbacks_list = [reduce_lr, tb_callback, cp_callback]\n","  \n","  hist = model.fit(\n","    train_generator, \n","    validation_data=val_generator,\n","    validation_steps=VAL_STEPS_PER_EPOCH,\n","    callbacks=callbacks_list,\n","    workers=16,\n","    max_queue_size=8, \n","    verbose=1, \n","    epochs=EPOCHS,\n","    steps_per_epoch=STEPS_PER_EPOCH,)"]},{"cell_type":"code","source":["def load_pretrained_model():\n","  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  model = load_model('/content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/model_vBaseline_mixed_precision - rwf/checkpoints/model.30.h5')\n","\n","  model.compile(optimizer=sgd,\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","  \n","  return model\n","  \n","model = load_pretrained_model()\n","model.summary()"],"metadata":{"id":"3ZSiR2sVUFhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"17zYehb5UtfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"jZcRA49pUthz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zusm9alrUtk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMrnr7LeeSIO"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XF7onohZbPhW"},"outputs":[],"source":["train_iter = iter(train_generator)\n","test_iter = iter(test_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVoth2uCZ2XR"},"outputs":[],"source":["train_batch = next(train_iter)\n","videos, labels = train_batch\n","mediapy.show_videos(videos)\n","\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7waK-MLPgRQe"},"outputs":[],"source":["videos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ql1-dZ_NajIG"},"outputs":[],"source":["videos, labels = next(test_iter)\n","\n","mediapy.show_videos(videos.numpy())\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQ4WV0Wtaql8"},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay6_FGq4ax2C"},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNRxPGbY5zTy"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPSJITGksMws"},"outputs":[],"source":["PATH_TENSORBOARD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxgZ5t6ww1Hk"},"outputs":[],"source":["%tensorboard --logdir /content/drive/MyDrive/ucf_experiments/ciclo_experimental_1/data/data_crop/model/runs/"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Train_Baseline with Blur and CONV LSTM 0.ipynb","provenance":[{"file_id":"1Y0Es-7qp0lKidIvDQtg1A95B_0nM0XUY","timestamp":1649245732503},{"file_id":"1NLkAOAFumeAKxsMA-hR0cFVVxh8s2OVn","timestamp":1649024032719},{"file_id":"12Jwm0NNThnZ4zOtLO9f8NboWGeLCmT97","timestamp":1648915960592},{"file_id":"18_hYXNSngi6puvDFPxZm8zPn_eUOrFDx","timestamp":1648858065542},{"file_id":"1iRVjGGuITI462fWGrokE2svB9ZZt4v5u","timestamp":1643675720779},{"file_id":"16WW39YDTR9IudeyKu3JS86yhUyDUCUT3","timestamp":1640226292514}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}